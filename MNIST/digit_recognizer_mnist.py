# -*- coding: utf-8 -*-
"""Digit Recognizer - MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DgNbIUuZ4_4W18IfZRi7cmIHFZT0gKLP
"""

import numpy as np 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import load_model

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

#  mounts the Google drive
from google.colab import drive
drive.mount('/content/drive')

# test path from the drive
test_path = '/content/drive/MyDrive/Kaggle/Digit_Recognizer/test.csv'

# train path from the drive
train_path = '/content/drive/MyDrive/Kaggle/Digit_Recognizer/train.csv'

# copying the file from drive to colab
!cp "{test_path}" .

# copying the file from drive to colab
!cp "{train_path}" .

test_df = pd.read_csv('test.csv')

train_df = pd.read_csv('train.csv')

train_df.head(2)

train_df.shape

test_df.shape

# Drop 'label' column
X_train = train_df.drop(labels = ["label"],axis = 1)

# only label column
Y_train = train_df["label"]

"""Each number amount:"""

plt.figure(figsize=(8,6))
sns.countplot(x = Y_train)
plt.show()

Y_train.value_counts()

"""# Preprocessing Data

## Missing values
"""

X_train.isnull().sum().agg(['count', 'mean', 'sum', 'min', 'max'])

test_df.isnull().sum().agg(['count', 'mean', 'sum', 'min', 'max'])

"""No missing values.

## Normalization

We should normalize the X data:
"""

X_train.iloc[0].max()

X_train.iloc[0].min()

X_train = X_train / 255.0
test_df = test_df / 255.0

X_train.iloc[0].max()

"""## Reshaping

Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1):
"""

X_train = X_train.values.reshape(-1,28,28,1)
test_df = test_df.values.reshape(-1,28,28,1)

single_image = plt.imshow(X_train[10][:,:,0], cmap='Greys')

"""
Our labels are literally categories of numbers. We need to translate this to be "one hot encoded" so our CNN can understand, otherwise it will think this is some sort of regression problem on a continuous axis. Keras has an easy to use function for this:"""

from tensorflow.keras.utils import to_categorical

Y_train[0]

Y_train_cat = to_categorical(Y_train)

print(Y_train_cat[0])

"""## Split training and valdiation set"""

# only 15% for validation set
X_train, X_valid, y_train, y_valid = train_test_split(X_train, Y_train_cat, test_size=0.15)

g = plt.imshow(X_train[5][:,:,0])

y_train[5]

"""## Creating and Training Model"""

model = Sequential()

# CONVOLUTIONAL LAYER
model.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=(28, 28, 1), activation='relu')) # filters almost always 2^n
# POOLING LAYER
model.add(MaxPool2D(pool_size=(2,2))) # in this case, half of the kernel size

# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER
model.add(Flatten())

# 128 NEURONS IN DENSE HIDDEN LAYER
model.add(Dense(128, activation='relu'))

# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES
model.add(Dense(10, activation='softmax'))  # SOFTMAX --> MULTICLASS PROBLEM

# https://keras.io/metrics/
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

model.summary()

early_stop = EarlyStopping(monitor='val_loss', patience=3)

model.fit(X_train, y_train, epochs=15, validation_data=(X_valid, y_valid), callbacks=[early_stop])

model.metrics_names

metrics = pd.DataFrame(model.history.history)

metrics

metrics[['loss', 'val_loss']].plot()
plt.show()

metrics[['accuracy', 'val_accuracy']].plot()
plt.show()

print(model.metrics_names)
print(model.evaluate(X_valid, y_valid, verbose = 0))

# model.save('mnist_CNN_kaggle_model.h5')

# grab model and scaler
mnist_model = load_model("mnist_CNN_kaggle_model.h5")

"""## Image Generator"""

image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees
                               width_shift_range=0.10, # Shift the pic width by a max of 5%
                               height_shift_range=0.10, # Shift the pic height by a max of 5%
                               #rescale=1/255, # our data is already scaled.
                               shear_range=0.1, # Shear means cutting away part of the image (max 10%)
                               zoom_range=0.1, # Zoom in by 10% max
                               horizontal_flip=True, # Allo horizontal flipping
                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value
                              )

# results = model.fit_generator(X_train, y_train, epochs=20,
#                               validation_data=[X_valid, y_valid],
#                               callbacks=[early_stop])

pred_test = mnist_model.predict(test_df)

pred_test.shape

# pred_test

pred_train = mnist_model.predict(X_train)

test_df.shape

X_train.shape

print(classification_report(y_train, pred_train))

y_train.shape

X_train.shape

