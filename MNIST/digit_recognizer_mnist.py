# -*- coding: utf-8 -*-
"""Digit Recognizer - MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DgNbIUuZ4_4W18IfZRi7cmIHFZT0gKLP
"""

import numpy as np 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, Flatten

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping

#  mounts the Google drive
from google.colab import drive
drive.mount('/content/drive')

# test path from the drive
test_path = '/content/drive/MyDrive/Kaggle/Digit_Recognizer/test.csv'

# train path from the drive
train_path = '/content/drive/MyDrive/Kaggle/Digit_Recognizer/train.csv'

# copying the file from drive to colab
!cp "{test_path}" .

# copying the file from drive to colab
!cp "{train_path}" .

test_df = pd.read_csv('test.csv')

train_df = pd.read_csv('train.csv')

train_df.head(2)

train_df.shape

test_df.shape

# Drop 'label' column
X_train = train_df.drop(labels = ["label"],axis = 1)

# only label column
Y_train = train_df["label"]

"""Each number amount:"""

plt.figure(figsize=(8,6))
sns.countplot(x = Y_train)
plt.show()

Y_train.value_counts()

"""# Preprocessing Data

## Missing values
"""

X_train.isnull().sum().agg(['count', 'mean', 'sum', 'min', 'max'])

test_df.isnull().sum().agg(['count', 'mean', 'sum', 'min', 'max'])

"""No missing values.

## Normalization

We should normalize the X data:
"""

X_train.iloc[0].max()

X_train.iloc[0].min()

X_train = X_train / 255.0
test_df = test_df / 255.0

X_train.iloc[0].max()

"""## Reshaping

Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1):
"""

X_train = X_train.values.reshape(-1,28,28,1)
test_df = test_df.values.reshape(-1,28,28,1)

single_image = plt.imshow(X_train[10][:,:,0], cmap='Greys')

"""
Our labels are literally categories of numbers. We need to translate this to be "one hot encoded" so our CNN can understand, otherwise it will think this is some sort of regression problem on a continuous axis. Keras has an easy to use function for this:"""

from tensorflow.keras.utils import to_categorical

Y_train[0]

Y_train_cat = to_categorical(Y_train)

print(Y_train_cat[0])

"""## Split training and valdiation set"""

# only 15% for validation set
X_train, X_valid, y_train, y_valid = train_test_split(X_train, Y_train_cat, test_size=0.15)

g = plt.imshow(X_train[5][:,:,0])

y_train[5]

"""## Creating and Training Model"""

model = Sequential()

# CONVOLUTIONAL LAYER
model.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=(28, 28, 1), activation='relu')) # filters almost always 2^n
# POOLING LAYER
model.add(MaxPool2D(pool_size=(2,2))) # in this case, half of the kernel size

# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER
model.add(Flatten())

# 128 NEURONS IN DENSE HIDDEN LAYER
model.add(Dense(128, activation='relu'))

# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES
model.add(Dense(10, activation='softmax'))  # SOFTMAX --> MULTICLASS PROBLEM

# https://keras.io/metrics/
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

model.summary()

early_stop = EarlyStopping(monitor='val_loss', patience=3)

model.fit(X_train, y_train, epochs=15, validation_data=(X_valid, y_valid), callbacks=[early_stop])

model.metrics_names

metrics = pd.DataFrame(model.history.history)

metrics

metrics[['loss', 'val_loss']].plot()
plt.show()

metrics[['accuracy', 'val_accuracy']].plot()
plt.show()

print(model.metrics_names)
print(model.evaluate(X_valid, y_valid, verbose = 0))

# model.save('mnist_CNN_kaggle_model.h5')

